{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70146340-369d-4d29-9181-a977259c0bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved ABl_1980__S__104-105_.xml to test_data/postprocessed/ABl_1980__S__104-105_.xml\n",
      "Processed and saved ABl_1980__S__1008-1016_.xml to test_data/postprocessed/ABl_1980__S__1008-1016_.xml\n",
      "Processed and saved ABl_1980__S__1024-1028_.xml to test_data/postprocessed/ABl_1980__S__1024-1028_.xml\n"
     ]
    }
   ],
   "source": [
    "# Script to transfer entities from a Named-entity recognition (NER) processed file to the original file.\n",
    "# This corrects unintended changes to the XML document that may have occurred during the TEI processing.\n",
    "# The NER-processed file is referred to as the \"edited file\".\n",
    "\n",
    "# pip install lxml\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Pfade für die verschiedenen Verzeichnisse\n",
    "edited_dir = 'test_data/TEI-XML_NER/error/Amtsblatt/'\n",
    "original_dir = 'test_data/TEI-XML/Amtsblatt/'\n",
    "output_dir = 'test_data/postprocessed/'\n",
    "\n",
    "\n",
    "## Helper functions\n",
    "\n",
    "# Helper function to check if an entity is nested within another entity\n",
    "def is_nested(tag):\n",
    "    \n",
    "        parent = tag.find_parent()\n",
    "        while parent:\n",
    "            if parent.name in {'placeName', 'persName', 'orgName'} and parent != tag:\n",
    "                return True\n",
    "            parent = parent.find_parent()\n",
    "        return False\n",
    "\n",
    "\n",
    "### Remove all nested entities from the list that are already contained within a parent entity\n",
    "def filter_nested_entities(entities):\n",
    "    \n",
    "    non_nested_entities = []\n",
    "\n",
    "    for entity in entities:\n",
    "        if not is_nested(entity):\n",
    "            non_nested_entities.append(entity)\n",
    "\n",
    "    return non_nested_entities\n",
    "\n",
    "\n",
    "def remove_entity_tags_in_str(text):\n",
    "    \n",
    "    # Regex-Muster für die Start- und End-Tags\n",
    "    tag_patterns = {\n",
    "        'placeName': r'</?placeName[^>]*>',\n",
    "        'persName': r'</?persName[^>]*>',\n",
    "        'orgName': r'</?orgName[^>]*>'\n",
    "    }\n",
    "    \n",
    "    # Entferne die Tags für jede Entität\n",
    "    for tag_name, pattern in tag_patterns.items():\n",
    "        # Entferne alle Start- und End-Tags für das aktuelle Tag\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_text_for_lookbehind(entity, removeEntityTags = True):\n",
    "    \n",
    "    parent_element = entity.find_parent()\n",
    "    \n",
    "    if parent_element:\n",
    "        \n",
    "        parent_text = ''.join(str(content) for content in parent_element.contents)\n",
    "        \n",
    "        entity_str = str(entity)\n",
    "        \n",
    "        index_of_child = parent_text.find(entity_str)\n",
    "\n",
    "        text_before_child_with_entities = parent_text[:index_of_child]\n",
    "\n",
    "        if not removeEntityTags:\n",
    "            # return 20 characters before entity tag as lookbehind text\n",
    "            return text_before_child_with_entities[-20:]\n",
    "\n",
    "        text_before_child_without_entities = remove_entity_tags_in_str(text_before_child_with_entities)\n",
    "\n",
    "        # return 30 characters before entity tag as lookbehind text\n",
    "        return text_before_child_without_entities[-30:]\n",
    "\n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "### Prepare the search text by removing all entities, so that the text matches the text in the original file\n",
    "def prepare_search_text(entity):\n",
    "    \n",
    "    # Remove entities within the parent entity\n",
    "    for inner_entity in entity.find_all(['placeName', 'persName', 'orgName']):\n",
    "        inner_entity.unwrap()  # Removes the tag but retains the content\n",
    "\n",
    "    # Also remove the parent entity to prepare the text for search\n",
    "    search_text = ''.join(str(content) for content in entity.contents)\n",
    "    \n",
    "    return search_text\n",
    "\n",
    "    \n",
    "###Insert ---DONE--- in each word in the replacement text to prevent the search term from being found again\n",
    "def insert_done_in_every_word(sentence):\n",
    "    \n",
    "    words = sentence.split()  # Satz in Wörter aufteilen\n",
    "    modified_words = []\n",
    "\n",
    "    pattern = re.compile(r'(<[^>]*>| )')\n",
    "    words = pattern.split(sentence)\n",
    "    \n",
    "    for word in words:\n",
    "        modified_word = word[:len(word)//2] + \"---DONE---\" + word[len(word)//2:]\n",
    "        modified_words.append(modified_word)\n",
    "    \n",
    "    # Die modifizierten Wörter zu einem neuen Satz zusammenfügen\n",
    "    modified_sentence = ''.join(modified_words)\n",
    "    \n",
    "    return modified_sentence\n",
    "\n",
    "    \n",
    "## Extract entities from the edited file and insert them into the original file (only within <body>)\n",
    "def merge_entities(original_xml, edited_xml):\n",
    "    \n",
    "    # Parse the original and edited XML\n",
    "    original_soup = BeautifulSoup(original_xml, 'xml')\n",
    "    edited_soup = BeautifulSoup(edited_xml, 'xml')\n",
    "\n",
    "    # Extract <body> content from both documents\n",
    "    original_body = original_soup.find('body')\n",
    "    edited_body = edited_soup.find('body')\n",
    "\n",
    "    # Ensure <body> exists in both documents\n",
    "    if original_body and edited_body:\n",
    "\n",
    "        # Find a list of all entities in the edited XML (places, people, organizations)\n",
    "        entities = edited_body.find_all(['placeName', 'persName', 'orgName'])\n",
    "\n",
    "        # Remove all entities that are already nested within another entity\n",
    "        non_nested_entities = filter_nested_entities(entities)\n",
    "\n",
    "        # Liste zum Speichern der nicht ersetzbaren Entitäten aus Runde eins\n",
    "        unreplaced_entities = []\n",
    "        \n",
    "        original_body_str = str(original_body)\n",
    "        \n",
    "        for entity in non_nested_entities:\n",
    "\n",
    "            searchText = prepare_search_text(copy.deepcopy(entity))\n",
    "\n",
    "            text_for_lookbehind = get_text_for_lookbehind(entity)\n",
    "            \n",
    "            # Insert text \"---DONE---\" multiple times in the replacement string to prevent the search term from being found again\n",
    "            replaceText = insert_done_in_every_word(str(entity))\n",
    "\n",
    "            context_pattern = (\n",
    "                r'(?<=' + re.escape(text_for_lookbehind) + r')\\s*' + re.escape(searchText)\n",
    "            )\n",
    "            \n",
    "            # Perform the replacement if lookbehind is found\n",
    "            original_body_str, count = re.subn(context_pattern, replaceText, original_body_str, count=1)\n",
    "\n",
    "            if count == 0:\n",
    "                # If no replacements were made, add the entity to the unreplaced list\n",
    "                unreplaced_entities.append(entity)\n",
    "\n",
    "        # Remove \"---DONE---\" texts\n",
    "        original_body_str = original_body_str.replace(\"---DONE---\", \"\")\n",
    "\n",
    "\n",
    "        # 2. Durchgang, um die noch nicht ersetzten Entitäten mit anderem Ansatz zu finden\n",
    "        for entity in unreplaced_entities:\n",
    "\n",
    "            searchText = prepare_search_text(copy.deepcopy(entity))\n",
    "\n",
    "            text_for_lookbehind = get_text_for_lookbehind(entity, removeEntityTags = False)\n",
    "            \n",
    "            # Don't insert text \"---DONE---\", because the purpose of the second round is to find the ones, which are not found in round one because of the already inserted entity tags in in the original body\n",
    "            replaceText = str(entity)\n",
    "\n",
    "            context_pattern = (\n",
    "                r'(?<=' + re.escape(text_for_lookbehind) + r')\\s*' + re.escape(searchText)\n",
    "            )\n",
    "    \n",
    "            # Perform the replacement if lookbehind is found, ignoring the tags\n",
    "            original_body_str = re.sub(context_pattern, replaceText, original_body_str, count=1)\n",
    "            \n",
    "\n",
    "        # Replace the old <body> with the new modified one in the original document\n",
    "        original_body.replace_with(BeautifulSoup(original_body_str, 'xml').body)\n",
    "        \n",
    "    return str(original_soup)\n",
    "\n",
    "\n",
    "##Dokumente verarbeiten: Einlesen, Entitäten übertragen, in neues File abspeichern\n",
    "###Falls der Zielordner nicht existiert, erstelle ihn\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "###Durchiteriere den Ordner mit den NER-Dokumenten\n",
    "for filename in os.listdir(edited_dir):\n",
    "    if filename.endswith('.xml'):  # Stelle sicher, dass nur XML-Dateien betrachtet werden\n",
    "        ###Pfad für das bearbeitete XML\n",
    "        edited_file_path = os.path.join(edited_dir, filename)\n",
    "        ###Pfad für das Original-XML\n",
    "        original_file_path = os.path.join(original_dir, filename)\n",
    "\n",
    "        ###Lese das bearbeitete XML in edited_xml\n",
    "        with open(edited_file_path, 'r', encoding='utf-8') as file:\n",
    "            edited_xml = file.read()\n",
    "\n",
    "        ###Lese das Original-XML in original_xml\n",
    "        if os.path.exists(original_file_path):  # Überprüfe, ob das Original existiert\n",
    "            with open(original_file_path, 'r', encoding='utf-8') as file:\n",
    "                original_xml = file.read()\n",
    "        else:\n",
    "            print(f\"Original file not found for {filename}\")\n",
    "            continue\n",
    "        \n",
    "        ###Result\n",
    "        result = merge_entities(original_xml, edited_xml)\n",
    "\n",
    "        ###Speichere das Result als XML-Dokument im postprocessed-Ordner ab\n",
    "        output_file_path = os.path.join(output_dir, filename)\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(result)\n",
    "\n",
    "        print(f\"Processed and saved {filename} to {output_file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04134054-cf48-49dc-aaba-4145691037a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
