{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb058336-acc2-4b05-bbd9-4e25e6646e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved ABl_1980__S__104-105_.xml to test_data/postprocessed/ABl_1980__S__104-105_.xml\n",
      "Processed and saved ABl_1980__S__1008-1016_.xml to test_data/postprocessed/ABl_1980__S__1008-1016_.xml\n",
      "Processed and saved ABl_1980__S__1024-1028_.xml to test_data/postprocessed/ABl_1980__S__1024-1028_.xml\n",
      "All files processed\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Script for correcting unintended text modifications during Named Entity Recognition (NER) \n",
    "\n",
    "This script addresses issues that may arise during the NER process \n",
    "according to the TEI standard, mostly unintended text duplications. \n",
    "An example of such a modification is:\n",
    ">>> (...) Seminar der Univer<lb break=\"no\" facs=\"#facs_290_r33\"/>sität</orgName>sität</cell>\n",
    "The script corrects this modification to:\n",
    ">>> (...) Seminar der Univer<lb break=\"no\" facs=\"#facs_290_r33\"/>sität</orgName></cell>\n",
    "\n",
    "The NER process checks the documents and detects errors. Documents with \n",
    "errors are saved in an /error folder. This script takes the NER-processed \n",
    "files with errors (hereafter referred to as the \"edited file\")  and extracts \n",
    "all TEI entities with some context. It then inserts the entities into the \n",
    "original file (before NER) using search and replace.\n",
    "\n",
    "The script accepts XML files (.xml) as input.\n",
    "\n",
    "Requirements:\n",
    "- This script requires that `beautifulsoup4` and `lxml` are installed in the Python environment where you are running this script.\n",
    "\n",
    "Installation of beautifulsoup4:\n",
    "- To install beautifulsoup4, run the following command in your command line:\n",
    "  ```bash\n",
    "  pip install beautifulsoup4\n",
    "\n",
    "Installation of lxml:\n",
    "- To install lxml, run the following command in your command line:\n",
    "  ```bash\n",
    "  pip install lxml\n",
    "\"\"\"\n",
    "\n",
    "# pip install beautifulsoup4\n",
    "# pip install lxml\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Paths for the various directories\n",
    "edited_dir = 'test_data/TEI-XML_NER/error/Amtsblatt/' # Directory containing NER-processed files with errors\n",
    "original_dir = 'test_data/TEI-XML/Amtsblatt/' # Directory containing the original files\n",
    "output_dir = 'test_data/postprocessed/' # Output directory for the merged files generated by this script\n",
    "\n",
    "\n",
    "\n",
    "def is_nested(entity):\n",
    "    \"\"\" Check if the current entity is nested within another entity.\n",
    "\n",
    "    Args:\n",
    "        entity (BeautifulSoup Tag): The entity (e.g., <placeName>, <persName>, <orgName>).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the entity is nested within another entity, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    parent = entity.find_parent()\n",
    "    while parent:\n",
    "        if parent.name in {'placeName', 'persName', 'orgName'} and parent != entity:\n",
    "            return True\n",
    "        parent = parent.find_parent()\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_nested_entities(entities):\n",
    "    \"\"\" Remove all nested entities from the list that are already contained within a parent entity\n",
    "\n",
    "    Args:\n",
    "        entities (list of BeautifulSoup Tags): List of entity tags from the edited XML.\n",
    "\n",
    "    Returns:\n",
    "        list of BeautifulSoup Tags: List of non-nested entities.\n",
    "    \"\"\"\n",
    "    \n",
    "    non_nested_entities = []\n",
    "\n",
    "    for entity in entities:\n",
    "        if not is_nested(entity):\n",
    "            non_nested_entities.append(entity)\n",
    "\n",
    "    return non_nested_entities\n",
    "\n",
    "\n",
    "def remove_entity_tags_in_str(text):\n",
    "    \"\"\" Remove all TEI entity tags (placeName, persName, orgName) from a string.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string that may contain TEI entity tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string with all TEI entity tags removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_patterns = {\n",
    "        'placeName': r'</?placeName[^>]*>',\n",
    "        'persName': r'</?persName[^>]*>',\n",
    "        'orgName': r'</?orgName[^>]*>'\n",
    "    }\n",
    "    \n",
    "    # Remove the tags for each entity type\n",
    "    for tag_name, pattern in tag_patterns.items():\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_text_for_lookbehind(entity, removeEntityTags = True):\n",
    "    \"\"\" Extract up to 30 characters of text before the entity, used for regex lookbehind.\n",
    "\n",
    "    Args:\n",
    "        entity (BeautifulSoup Tag): The entity tag from which to extract the lookbehind text.\n",
    "        removeEntityTags (bool, optional): Whether to remove nested entity tags from the lookbehind text. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: The 30 characters (if removeEntityTags is false) or 20 characters (otherwise) before the entity in the parent element.\n",
    "    \"\"\"\n",
    "    \n",
    "    parent_element = entity.find_parent()\n",
    "    \n",
    "    if parent_element:\n",
    "        parent_text = ''.join(str(content) for content in parent_element.contents)\n",
    "        entity_str = str(entity)\n",
    "        index_of_child = parent_text.find(entity_str)\n",
    "        text_before_child_with_entities = parent_text[:index_of_child]\n",
    "\n",
    "        if not removeEntityTags:\n",
    "            # return 20 characters before entity tag as lookbehind text\n",
    "            return text_before_child_with_entities[-20:]\n",
    "\n",
    "        text_before_child_without_entities = remove_entity_tags_in_str(text_before_child_with_entities)\n",
    "\n",
    "        # return 30 characters before entity tag as lookbehind text\n",
    "        return text_before_child_without_entities[-30:]\n",
    "\n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "def prepare_search_text(entity):\n",
    "    \"\"\" Prepare the search text by removing all entity tags from the entity. \n",
    "        This will make the text match the text in the original file (before NER).\n",
    "\n",
    "    Args:\n",
    "        entity (BeautifulSoup Tag): The entity whose text is being prepared.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned entity text, without any nested tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove all nested entities inside the current entity\n",
    "    for inner_entity in entity.find_all(['placeName', 'persName', 'orgName']):\n",
    "        inner_entity.unwrap()  # Removes the tag but retains the content\n",
    "\n",
    "    # Also remove the parent entity to prepare the text for search\n",
    "    search_text = ''.join(str(content) for content in entity.contents)\n",
    "    \n",
    "    return search_text\n",
    "\n",
    "    \n",
    "def insert_done_in_every_word(sentence):\n",
    "    \"\"\" Insert the marker `---DONE---` into each word of the replacement string\n",
    "    to prevent repeated matches during the search-and-replace process.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The sentence or entity text in which to insert the marker.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified sentence with `---DONE---` inserted.\n",
    "    \"\"\"\n",
    "    \n",
    "    modified_words = []\n",
    "\n",
    "    pattern = re.compile(r'(<[^>]*>| )')\n",
    "    words = pattern.split(sentence)\n",
    "    \n",
    "    for word in words:\n",
    "        modified_word = word[:len(word)//2] + \"---DONE---\" + word[len(word)//2:]\n",
    "        modified_words.append(modified_word)\n",
    "    \n",
    "    modified_sentence = ''.join(modified_words)\n",
    "    \n",
    "    return modified_sentence\n",
    "\n",
    "    \n",
    "def merge_entities(original_xml, edited_xml):\n",
    "    \"\"\" Merge the named entities from the edited XML into the original XML (only within <body>).\n",
    "\n",
    "    Args:\n",
    "        original_xml (str): The XML content of the original file.\n",
    "        edited_xml (str): The XML content of the NER-processed file with errors.\n",
    "\n",
    "    Returns:\n",
    "        str: The original XML content with the corrected entities inserted.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse the original and edited XML\n",
    "    original_soup = BeautifulSoup(original_xml, 'xml')\n",
    "    edited_soup = BeautifulSoup(edited_xml, 'xml')\n",
    "\n",
    "    # Extract <body> content from both documents\n",
    "    original_body = original_soup.find('body')\n",
    "    edited_body = edited_soup.find('body')\n",
    "\n",
    "    # Ensure <body> exists in both documents\n",
    "    if original_body and edited_body:\n",
    "        \n",
    "        # Find all entities in the edited XML (places, people, organizations)\n",
    "        entities = edited_body.find_all(['placeName', 'persName', 'orgName'])\n",
    "\n",
    "        # Remove all entities that are already nested within another entity\n",
    "        non_nested_entities = filter_nested_entities(entities)\n",
    "\n",
    "        # List to store entities that couldn't be replaced in the round one\n",
    "        unreplaced_entities = []\n",
    "        \n",
    "        original_body_str = str(original_body)\n",
    "\n",
    "        # Round one using greater context (lookbehind) and ignoring entity tags   \n",
    "        for entity in non_nested_entities:\n",
    "            \n",
    "            searchText = prepare_search_text(copy.deepcopy(entity))\n",
    "            text_for_lookbehind = get_text_for_lookbehind(entity)\n",
    "            \n",
    "            # Insert \"---DONE---\" in replacement text to prevent re-matching\n",
    "            replaceText = insert_done_in_every_word(str(entity))\n",
    "\n",
    "            # Create the regex pattern for contextual replacement\n",
    "            context_pattern = (\n",
    "                r'(?<=' + re.escape(text_for_lookbehind) + r')\\s*' + re.escape(searchText)\n",
    "            )\n",
    "            \n",
    "            # Perform the replacement if the lookbehind is found\n",
    "            original_body_str, count = re.subn(context_pattern, replaceText, original_body_str, count=1)\n",
    "\n",
    "            if count == 0:\n",
    "                # If no replacements were made, add the entity to the unreplaced list\n",
    "                unreplaced_entities.append(entity)\n",
    "\n",
    "        # Remove \"---DONE---\" markers\n",
    "        original_body_str = original_body_str.replace(\"---DONE---\", \"\")\n",
    "\n",
    "\n",
    "        # Round two uses a shorter context and considers the presence of entity tags. \n",
    "        # A possible reason for the previous lookbehind not matching could be that an entity \n",
    "        # has already been inserted into the original file, causing the current lookbehind \n",
    "        # to fail when trying to match with the next entity's surrounding text.\n",
    "        for entity in unreplaced_entities:\n",
    "            \n",
    "            searchText = prepare_search_text(copy.deepcopy(entity))\n",
    "            text_for_lookbehind = get_text_for_lookbehind(entity, removeEntityTags = False)\n",
    "            \n",
    "            # Do not insert \"---DONE---\" in this round. The purpose of the second round is to find entities \n",
    "            # that were missed in the first round due to already inserted entity tags in the original document.\n",
    "            replaceText = str(entity)\n",
    "\n",
    "            context_pattern = (\n",
    "                r'(?<=' + re.escape(text_for_lookbehind) + r')\\s*' + re.escape(searchText)\n",
    "            )\n",
    "    \n",
    "            original_body_str = re.sub(context_pattern, replaceText, original_body_str, count=1)\n",
    "            \n",
    "\n",
    "        # Replace the old <body> with the modified version in the original document\n",
    "        original_body.replace_with(BeautifulSoup(original_body_str, 'xml').body)\n",
    "        \n",
    "    return str(original_soup)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\" Process XML documents by reading, merging entities, and saving the results.\n",
    "\n",
    "    This function reads NER-processed XML files,\n",
    "    merges the identified entities into the corresponding original files,\n",
    "    and then saves the merged output into a new directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists, create it if necessary\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for filename in os.listdir(edited_dir):\n",
    "        \n",
    "        if filename.endswith('.xml'):\n",
    "\n",
    "            # Read edited and original xml file\n",
    "            edited_file_path = os.path.join(edited_dir, filename)\n",
    "            original_file_path = os.path.join(original_dir, filename)\n",
    "    \n",
    "            with open(edited_file_path, 'r', encoding='utf-8') as file:\n",
    "                edited_xml = file.read()\n",
    "    \n",
    "            if os.path.exists(original_file_path): \n",
    "                with open(original_file_path, 'r', encoding='utf-8') as file:\n",
    "                    original_xml = file.read()\n",
    "            else:\n",
    "                print(f\"Original file not found for {filename}\")\n",
    "                continue\n",
    "    \n",
    "            # Merge entities from the edited file into the original file\n",
    "            result = merge_entities(original_xml, edited_xml)\n",
    "    \n",
    "            # Save the merged result to the output directory as an XML document\n",
    "            output_file_path = os.path.join(output_dir, filename)\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(result)\n",
    "    \n",
    "            print(f\"Processed and saved {filename} to {output_file_path}\")\n",
    "\n",
    "    print(f\"All files processed\")\n",
    "\n",
    "# Let the magic happen\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723d0c2-ebd3-4fa7-bee6-6df62f2343e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
